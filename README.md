# **Retrieval-Augmented Generation (RAG) Web Article Chatbot**  
**A Streamlit + LangChain + Mistral AI application for querying web articles using RAG.**  

## **ðŸ“Œ Overview**  
This project implements a **Retrieval-Augmented Generation (RAG)** system that:  
1. **Loads** a web article from a given URL.  
2. **Processes & Splits** the text into chunks.  
3. **Generates Embeddings** using HuggingFace's BGE model.  
4. **Stores** them in a Chroma vector database.  
5. **Answers questions** using Mistral AI's LLM with document retrieval.  

The frontend is built with **Streamlit**, providing an interactive chat interface.  

---

## **ðŸš€ Features**  
âœ” **Web Article Retrieval** â€“ Extract and process content from any URL.  
âœ” **Chunking & Embeddings** â€“ Splits text into manageable chunks and generates embeddings.  
âœ” **Vector Search** â€“ Uses ChromaDB for efficient document retrieval.  
âœ” **Chat Interface** â€“ Streamlit-powered UI for interactive Q&A.  
âœ” **Mistral AI Integration** â€“ Leverages `mistral-large-latest` for high-quality responses.  

---

## **ðŸ›  Setup & Installation**  

### **1. Clone the Repository**  
```bash
git clone https://github.com/your-username/your-repo.git
cd your-repo
```

### **2. Create & Activate a Virtual Environment**  
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
.\venv\Scripts\activate  # Windows
```

### **3. Install Dependencies**  
```bash
pip install -r requirements.txt
```

### **4. Set Up Mistral API Key**  
Replace `your-api-key` in `langchain_helper.py` with your actual [Mistral AI API key](https://console.mistral.ai/).  

---

## **ðŸ’» Usage**  
1. **Run the Streamlit App**  
   ```bash
   streamlit run main.py
   ```
2. **Enter a URL** in the sidebar.  
3. **Ask questions** in the chat interface.  

Example:  
- **URL:** `https://en.wikipedia.org/wiki/Large_language_model`  
- **Question:** *"What are the key applications of LLMs?"*  

---

## **ðŸ“‚ Project Structure**  
```
â”œâ”€â”€ main.py                # Streamlit UI & chat logic  
â”œâ”€â”€ langchain_helper.py    # LangChain RAG pipeline  
â”œâ”€â”€ requirements.txt       # Python dependencies  
â””â”€â”€ README.md              # This file  
```

---

## **ðŸ”§ Dependencies**  
- `streamlit` â€“ Web UI  
- `langchain` â€“ RAG pipeline  
- `mistralai` â€“ Mistral LLM integration  
- `chromadb` â€“ Vector storage  
- `unstructured` â€“ Web document loading  
- `huggingface-hub` â€“ Embeddings  

---


### **ðŸŽ‰ Happy Querying!** ðŸŽ‰  
Deploy this to **Hugging Face Spaces** or **Streamlit Cloud** for easy sharing! ðŸš€  

---

**ðŸ”— Related Projects:**  
- [LangChain Documentation](https://python.langchain.com/)  
- [Mistral AI API](https://docs.mistral.ai/)  
- [ChromaDB Guide](https://docs.trychroma.com/)  

---
